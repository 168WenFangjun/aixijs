
<!DOCTYPE html>
<html>

<head>
    <title>
        General Reinforcement Learning Demo
    </title>
    <link rel="stylesheet" href="style.css">
    <meta charset="UTF-8">
	<script type="text/javascript" src="lib/demo.js"></script>
	<script type="text/javascript" src="lib/plot.js"></script>
	<script type="text/javascript" src="lib/environment.js"></script>
	<script type="text/javascript" src="lib/tile.js"></script>
	<script type="text/javascript" src="lib/agent.js"></script>
	<script type="text/javascript" src="lib/bayes.js"></script>
	<script type="text/javascript" src="lib/search.js"></script>
	<script type="text/javascript" src="lib/trace.js"></script>
	<script type="text/javascript" src="lib/visualization.js"></script>
	<script type="text/javascript" src="lib/util.js"></script>
	<script type="text/javascript" src="lib/options.js"></script>
	<script type="text/javascript" src="lib/config.js"></script>
	<script type="text/javascript" src="lib/distribution.js"></script>

	<script type="text/javascript" src="external/mathjs-3.1.4.min.js"></script>
	<script type="text/javascript" src="external/jquery-2.2.3.min.js"></script>
	<script type="text/javascript" src="external/d3-3.5.16.min.js"></script>
	<script type="text/javascript" src="external/marked-0.3.5.js"></script>

	<script>
		function renderMarkdown() {
			$(".md").each(function(x) {
				$(this).html(marked($(this).html()))
			})
			renderJax()
		}

		var jaxrendered = false;
		function renderJax() {
			if (jaxrendered) {return}
			(function () {
				var script = document.createElement("script");
				script.type = "text/javascript";
				script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
				document.getElementsByTagName("head")[0].appendChild(script);
				jaxrendered = true;
			})();
		}
	</script>
</head>

<body onload="Demo.init();renderMarkdown()">

<div class="header">
    <h1>General Reinforcement Learning Demo</h1>
    <hr />
</div>

<!-- Vis -->
<table>
	<tr>
		<td width="40%">
			<span>
				<span id="gridvis" style="display: none"></span>
				<!-- Navigation -->
			    <span id="navigation" style="display: none">
			        <h3>Navigation</h3>
			        <p>
			            <input type="range" name="slider" id="slider" min="0" value="0" oninput="demo.vis.jumpTo(value)">
			            <button onclick="demo.vis.jumpTo(0);demo.vis.pause()">|&lt;&lt;</button>
			            <button onclick="demo.vis.pause()">||</button>
			            <button onclick="demo.vis.run(300)">&gt;</button>
			            <button onclick="demo.vis.run(50)">&gt;&gt;</button>
			            <button onclick="demo.vis.run(1)">&gt;&gt;&gt;</button>
			        </p>
			        <form>
			            <p class="monitor">
			                <label for="display_time">Cycle</label>
			                <input class="display" type="text" name="Time" id="display_time" value="0" readonly>
			            </p>
			            <p class="monitor">
			                <label for="r_ave">Average Reward</label>
			                <input class="display" type="text" name="Reward" id="r_ave" value="" readonly>
			            </p>
			        </form>
			    </span>

				<!-- Demo Parameters -->
			    <span id="setup">
			        <h3>Setup</h3>
			        <form id="param_form">
			            <p class="params" id="p_select" style="display: table-row">
			                <label for="demo_select">Demo:</label>
			                <select id="demo_select" name="demo_select" onchange="Demo.setOptions()" required>
								<option selected disabled hidden style="display: none" value="" label=" "></option>
							</select>
			            </p>
			            <p class="params" id="p_alpha">
			                <label title="Learning rate">Alpha:</label>
			                <input type="number" class="params" name="alpha" id="alpha" min="0" max="1" step="0.01" required>
			            </p>
			            <p class="params" id="p_gamma">
			                <label title="Discount rate (geometric)">Gamma:</label>
			                <input type="number" class="params" name="gamma" id="gamma" min="0" max="1" step="0.01" required>
			            </p>
			            <p class="params" id="p_epsilon">
			                <label title="Exploration rate">Epsilon:</label>
			                <input type="number" class="params" name="epsilon" id="epsilon" min="0" max="1" step="0.01" required>
			            </p>
						<p class="params" id="p_horizon">
			                <label title="Planning horizon">Horizon:</label>
			                <input type="number" class="params" name="horizon" id="horizon" min="1" max="100" step="1" required>
			            </p>
						<p class="params" id="p_samples">
			                <label title="Number of MCTS samples">MCTS Samples:</label>
			                <input type="number" class="params" name="samples" id="samples" min="1" max="10000" step="1" required>
			            </p>
						<p class="params" id="p_ucb">
			                <label title="UCB exploration parameter">UCB Weight:</label>
			                <input type="number" class="params" name="ucb" id="ucb" min="0.01" max="10" step="0.01" required>
			            </p>
			            <p class="params" id="p_cycles">
			                <label title="Number of cycles to run the simulation for">Cycles:</label>
			                <input type="number" class="params" name="cycles" id="cycles" min="1" max="1000000" step="1" required>
			            </p>
						<input type="submit" value="Run" onclick="Demo.run(document)">
					</form>
					<script>
						$("#param_form").submit(event => event.preventDefault())
					</script>
			    </span>
			</span>
		</td>
		<td valign="top">
			<span id="plots"></span>
		<td/>
	</tr>
	<tr>

<!-- Explanations -->
<td colspan=2>
<span class="md" id="qlearn_exp" style="display:none">
---
# Tabular Q-Learning
</span>

<span class="md" id="bayes_exp" style="display:none">
---
# The Bayes Agent - AI\\(\xi\\)
All Bayes agents have a mixture model of the form
$$
\xi(x) = \sum\_{\nu\in\mathcal{M}}w\_{\nu}\nu(x).
$$
Given some history of observations \\(h=(x\_1\dots x\_{t-1})\\) and a new observation \\(x\_t\\), we interpet \\(p(x|\nu)=\nu(x\_t|h)\\) and \\(p(\nu|h)=w\_\nu\\), and so we update with Bayes' rule:
$$
p(\nu|x\_t) = \frac{p(x|\nu)p(\nu)}{p(x\_t)}\\
= \frac{\nu(x\_t|h)w\_\nu}{\sum\_{\nu'\in\mathcal{M}}w\_\nu'\nu'(x\_t)}.
$$
AI\\(\xi\\) is the Bayes-optimal reinforcement learning agent:
$$
a\_{t}^{\text{AI}\xi} = \arg\max\_{a\_t}\sum\_{e\_t}\cdots\max\_{a\_\infty}\sum\_{e\_\infty}\sum\_{k=t}^{\infty}\gamma\_k r\_k \xi(e\_k|ae\_{\lt k}).
$$

Note that this is not to be confused with AIXI, which uses Solomonoff's Universal prior as its belief distribution:
$$
\xi^{\text{AIXI}}(e\_k|ae\_{\lt k}) = \sum\_{q\ :\ U(q;a\_{\lt k})=e\_{1:k}}2^{-l(q)}
$$
</span>

<span class="md" id="aimu_exp" style="display:none">
---
# The Informed Agent - AI\\(\mu\\)
AI\\(\mu\\) doesn't learn; it is just the expectimax solution. This is the stochastic analogue of minimax for deterministic games:
$$
a\_{t}^{\text{AI}\mu} = \arg\max\_{a\_t}\sum\_{e\_t}\cdots\max\_{a\_\infty}\sum\_{e\_\infty}\sum\_{k=t}^{\infty}\gamma\_k r\_k \mu(e\_k|ae\_{\lt k}).
$$
</span>

<span class="md" id="ksa_exp" style="display:none">
---
# Knowledge Seeking Agents (KSA)
If we generalise from reinforcement-learning agents to _utility_ agents, we can naturally define several several types of KSA which seek to minimize entropy / maximize information gain.

The \\(d\\)-expected information gain is given by TODO
</span>

<span class="md" id="thompson_exp" style="display:none">
---
# Thompson Sampling
</span>
</td>
</tr>
</table>

</body>
</html>
