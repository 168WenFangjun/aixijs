{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "agents = {'BayesAgent':(r'AI$\\xi$','purple'),\n",
    "          'Knowledge-seeking agent':('Kullback-Leibler','blue'),\n",
    "          'KullbackLeiblerKSA':('Kullback-Leibler','blue'),\n",
    "          'ShannonKSA':('Shannon','green'),\n",
    "          'SquareKSA':('Square','red'),\n",
    "          'Shannon KSA':('Shannon','green'),\n",
    "          'Square KSA':('Square','red'),\n",
    "          'ThompsonAgent':('Thompson','yellow'),\n",
    "          'QLearn':('Q-Learning','black'),\n",
    "          'KSA-Dirichlet': ('Kullback-Leibler','blue'),\n",
    "          'Entropy-seeking agent': ('Shannon','green'),\n",
    "          'Square KSA-Dirichlet': ('Square','red')}\n",
    "\n",
    "\n",
    "def plot_results(directory,filename='results-1',objective=None,outfile=None):\n",
    "    if not objective:\n",
    "        if 'ksa' in directory:\n",
    "            objective = 'explored'\n",
    "        else:\n",
    "            objective = 'rewards'\n",
    "    if objective == 'rewards':\n",
    "        y_axis = 'Average Reward'\n",
    "    elif objective == 'explored':\n",
    "        y_axis = 'Exploration (%)'\n",
    "    \n",
    "    file = open(directory + '/' + filename + '.json')\n",
    "    data = json.load(file)\n",
    "    file.close()\n",
    "\n",
    "    fig = plt.figure(figsize=(12,8),dpi=200)\n",
    "    for i,k in enumerate(data):\n",
    "        try:\n",
    "            d = data[k]\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "        cycles = d[0]['cycles']\n",
    "        runs = len(d)\n",
    "\n",
    "        A = np.zeros((cycles,runs))\n",
    "        for j in range(runs):\n",
    "            A[:,j] = np.array(d[j][objective])\n",
    "        mu = np.mean(A,1)\n",
    "        sigma = np.std(A,1)\n",
    "        a = np.max(np.vstack((mu-sigma,np.min(A,1))),0)\n",
    "        b = np.min(np.vstack((mu+sigma,np.array(cycles*[100]))),0)\n",
    "\n",
    "        if k in agents:\n",
    "            lab = agents[k][0]\n",
    "\n",
    "        color = agents[k][1]\n",
    "        alpha = 0.2\n",
    "        plt.plot(a,color=color,alpha=alpha)\n",
    "        plt.plot(b,color=color,alpha=alpha)\n",
    "        plt.plot(mu,label=lab,color=color,lw=3)\n",
    "        plt.fill_between(np.arange(cycles),a,b,alpha=alpha,color=color)\n",
    "\n",
    "    plt.xlabel('Cycles',fontsize=25)\n",
    "    plt.ylabel(y_axis,fontsize=25)\n",
    "    plt.legend(loc='lower right',fontsize=25)\n",
    "    \n",
    "    if outfile:\n",
    "        plt.savefig(directory + '/' + outfile + '.png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "plot_results('ksa',outfile='plot-paper')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
